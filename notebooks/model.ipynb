{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkdJOxFa1_bq",
        "outputId": "37c92148-3865-492b-f208-8290ef3d4fcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8QtLZLou6WwU",
        "outputId": "b39388c6-bd38-43ad-8e96-162784bed8a5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1nLL5DNOyzlfE3_Obr8tg83RSxo_WDfRS/Real_Estate_Classification'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "root_dir = \"/content/drive/MyDrive/Real_Estate_Classification\"\n",
        "path = os.chdir(root_dir)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZQh8F482rlV"
      },
      "source": [
        "## Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s7XAqVmV2PwE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9znjDZ02xNF"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QwjFMfI62tWA",
        "outputId": "e4e747e7-96f7-464d-80bf-613f8819e113"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e037378d-7412-49ac-a773-be8b16d962f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>labels</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>REMIS_Image_Dataset/investor/rever_phu-my-thua...</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>investor</td>\n",
              "      <td>Train0.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>REMIS_Image_Dataset/others/10215375959772007.jpeg</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>others</td>\n",
              "      <td>Train1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>REMIS_Image_Dataset/project/duanbatdongsan_pj5...</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>project</td>\n",
              "      <td>Train2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>REMIS_Image_Dataset/post/123nhadat_4321333_0.jpg</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>post</td>\n",
              "      <td>Train3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>REMIS_Image_Dataset/investor/rever_keppel-land...</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>investor</td>\n",
              "      <td>Train4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895</th>\n",
              "      <td>REMIS_Image_Dataset/investor/rever_tan-thanh-d...</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>investor</td>\n",
              "      <td>Train895.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>896</th>\n",
              "      <td>REMIS_Image_Dataset/others/10153721284885397.jpeg</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>others</td>\n",
              "      <td>Train896.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897</th>\n",
              "      <td>REMIS_Image_Dataset/others/3744275319541.jpeg</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>others</td>\n",
              "      <td>Train897.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>898</th>\n",
              "      <td>REMIS_Image_Dataset/others/1012645588840463.jpeg</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>others</td>\n",
              "      <td>Train898.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>899</th>\n",
              "      <td>REMIS_Image_Dataset/project/duanbatdongsan_pj5...</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>project</td>\n",
              "      <td>Train899.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>900 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e037378d-7412-49ac-a773-be8b16d962f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e037378d-7412-49ac-a773-be8b16d962f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e037378d-7412-49ac-a773-be8b16d962f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  path         label  \\\n",
              "0    REMIS_Image_Dataset/investor/rever_phu-my-thua...  [1, 0, 0, 0]   \n",
              "1    REMIS_Image_Dataset/others/10215375959772007.jpeg  [0, 1, 0, 0]   \n",
              "2    REMIS_Image_Dataset/project/duanbatdongsan_pj5...  [0, 0, 0, 1]   \n",
              "3     REMIS_Image_Dataset/post/123nhadat_4321333_0.jpg  [0, 0, 1, 0]   \n",
              "4    REMIS_Image_Dataset/investor/rever_keppel-land...  [1, 0, 0, 0]   \n",
              "..                                                 ...           ...   \n",
              "895  REMIS_Image_Dataset/investor/rever_tan-thanh-d...  [1, 0, 0, 0]   \n",
              "896  REMIS_Image_Dataset/others/10153721284885397.jpeg  [0, 1, 0, 0]   \n",
              "897      REMIS_Image_Dataset/others/3744275319541.jpeg  [0, 1, 0, 0]   \n",
              "898   REMIS_Image_Dataset/others/1012645588840463.jpeg  [0, 1, 0, 0]   \n",
              "899  REMIS_Image_Dataset/project/duanbatdongsan_pj5...  [0, 0, 0, 1]   \n",
              "\n",
              "       labels          name  \n",
              "0    investor    Train0.jpg  \n",
              "1      others    Train1.jpg  \n",
              "2     project    Train2.jpg  \n",
              "3        post    Train3.jpg  \n",
              "4    investor    Train4.jpg  \n",
              "..        ...           ...  \n",
              "895  investor  Train895.jpg  \n",
              "896    others  Train896.jpg  \n",
              "897    others  Train897.jpg  \n",
              "898    others  Train898.jpg  \n",
              "899   project  Train899.jpg  \n",
              "\n",
              "[900 rows x 4 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = pd.read_csv(\"REMIS_Image_Dataset/train_re.csv\")\n",
        "train_df['labels'] = [train_df['path'].str.split('\\\\')[i][1] for i in range(len(train_df['path']))]\n",
        "train_df['path'] = train_df['path'].str.replace('Dataset', 'REMIS_Image_Dataset')\n",
        "train_df['path'] = train_df['path'].str.replace('\\\\', '/')\n",
        "train_df['name'] = ['Train' + str(i) + '.jpg' for i in range(len(train_df['path'])) ]\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EpIDIGko22mf",
        "outputId": "e14d56d4-de5a-4be9-81f8-46640cc47225"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-16de22f7-b278-4e2b-8cde-50974d8f585a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>labels</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>REMIS_Image_Dataset/others/837645183007172.jpeg</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>others</td>\n",
              "      <td>Test0.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>REMIS_Image_Dataset/post/123nhadat_4321799_4.jpg</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>post</td>\n",
              "      <td>Test1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>REMIS_Image_Dataset/others/10208474191744749.jpeg</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>others</td>\n",
              "      <td>Test2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>REMIS_Image_Dataset/investor/rever_bat-dong-sa...</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>investor</td>\n",
              "      <td>Test3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>REMIS_Image_Dataset/project/duanbatdongsan_pj5...</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>project</td>\n",
              "      <td>Test4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>REMIS_Image_Dataset/investor/rever_gia-tue_0.jpg</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>investor</td>\n",
              "      <td>Test255.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>REMIS_Image_Dataset/post/123nhadat_4310483_0.jpg</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>post</td>\n",
              "      <td>Test256.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>REMIS_Image_Dataset/others/10200930046625836.jpeg</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>others</td>\n",
              "      <td>Test257.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>REMIS_Image_Dataset/others/1047558682015820.jpeg</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>others</td>\n",
              "      <td>Test258.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>REMIS_Image_Dataset/post/123nhadat_4320411_0.jpg</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>post</td>\n",
              "      <td>Test259.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>260 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16de22f7-b278-4e2b-8cde-50974d8f585a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16de22f7-b278-4e2b-8cde-50974d8f585a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16de22f7-b278-4e2b-8cde-50974d8f585a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  path         label  \\\n",
              "0      REMIS_Image_Dataset/others/837645183007172.jpeg  [0, 1, 0, 0]   \n",
              "1     REMIS_Image_Dataset/post/123nhadat_4321799_4.jpg  [0, 0, 1, 0]   \n",
              "2    REMIS_Image_Dataset/others/10208474191744749.jpeg  [0, 1, 0, 0]   \n",
              "3    REMIS_Image_Dataset/investor/rever_bat-dong-sa...  [1, 0, 0, 0]   \n",
              "4    REMIS_Image_Dataset/project/duanbatdongsan_pj5...  [0, 0, 0, 1]   \n",
              "..                                                 ...           ...   \n",
              "255   REMIS_Image_Dataset/investor/rever_gia-tue_0.jpg  [1, 0, 0, 0]   \n",
              "256   REMIS_Image_Dataset/post/123nhadat_4310483_0.jpg  [0, 0, 1, 0]   \n",
              "257  REMIS_Image_Dataset/others/10200930046625836.jpeg  [0, 1, 0, 0]   \n",
              "258   REMIS_Image_Dataset/others/1047558682015820.jpeg  [0, 1, 0, 0]   \n",
              "259   REMIS_Image_Dataset/post/123nhadat_4320411_0.jpg  [0, 0, 1, 0]   \n",
              "\n",
              "       labels         name  \n",
              "0      others    Test0.jpg  \n",
              "1        post    Test1.jpg  \n",
              "2      others    Test2.jpg  \n",
              "3    investor    Test3.jpg  \n",
              "4     project    Test4.jpg  \n",
              "..        ...          ...  \n",
              "255  investor  Test255.jpg  \n",
              "256      post  Test256.jpg  \n",
              "257    others  Test257.jpg  \n",
              "258    others  Test258.jpg  \n",
              "259      post  Test259.jpg  \n",
              "\n",
              "[260 rows x 4 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df = pd.read_csv(\"REMIS_Image_Dataset/test_re.csv\")\n",
        "test_df['labels'] = [test_df['path'].str.split('\\\\')[i][1] for i in range(len(test_df['path']))]\n",
        "test_df['path'] = test_df['path'].str.replace('Dataset', 'REMIS_Image_Dataset')\n",
        "test_df['path'] = test_df['path'].str.replace('\\\\', '/')\n",
        "test_df['name'] = ['Test' + str(i) + '.jpg' for i in range(len(test_df['path'])) ]\n",
        "test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVz5k3OL9F5z"
      },
      "source": [
        "## Create training and testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KJ9DJvY7HUG"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  os.mkdir('data')\n",
        "  os.mkdir('data/training')\n",
        "  os.mkdir('data/testing')\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvg38nWb9V5R"
      },
      "outputs": [],
      "source": [
        "for i, path in enumerate(train_df['path']):\n",
        "  try:\n",
        "    shutil.copy(path, \"data/training/Train\"+str(i)+\".jpg\")\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "for i, path in enumerate(test_df['path']):\n",
        "  try:\n",
        "    shutil.copy(path, \"data/testing/Test\"+str(i)+\".jpg\")\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak0Ig4kH_rJ6",
        "outputId": "1d622ee8-58dc-4a6f-bcc0-ccb596c9e6f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 900 validated image filenames belonging to 4 classes.\n",
            "Found 260 validated image filenames belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "## Initalize Image Data Generator with Augmentation\n",
        "train_data_generator = ImageDataGenerator(rescale=1./255,\n",
        "        rotation_range=180,\n",
        "        zoom_range=0.1,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        brightness_range = (0.9,1.1),\n",
        "        fill_mode='nearest')\n",
        "\n",
        "\n",
        "## Recreate datasets from dataframe\n",
        "train_data_multi = train_data_generator.flow_from_dataframe(dataframe=train_df,\n",
        "                                                    directory=\"data/training\",\n",
        "                                                    x_col=\"name\",\n",
        "                                                    y_col= \"labels\",\n",
        "                                                    target_size=(224, 224),\n",
        "                                                    class_mode='categorical',\n",
        "                                                    batch_size=16,\n",
        "                                                    shuffle=True,\n",
        "                                                    seed=42)\n",
        "\n",
        "test_data_generator = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "test_data_multi = train_data_generator.flow_from_dataframe(dataframe=test_df,\n",
        "                                                    directory=\"data/testing\",\n",
        "                                                    x_col=\"name\",\n",
        "                                                    y_col= \"labels\",\n",
        "                                                    target_size=(224, 224),\n",
        "                                                    class_mode='categorical',\n",
        "                                                    batch_size=16,\n",
        "                                                    shuffle=True,\n",
        "                                                    seed=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZlgwqetD30e"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxNJv_H-Doz_"
      },
      "source": [
        "## Custom Callbacks function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ksf55stbDzRM"
      },
      "source": [
        "### Create new metrics for monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fPPZlTRMDSx1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "class Metrics(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, valid_data):\n",
        "        super(Metrics, self).__init__()\n",
        "        self.validation_data = valid_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        val_predict = np.argmax(self.model.predict(self.validation_data[0]), -1)\n",
        "        val_targ = self.validation_data[1]\n",
        "        if len(val_targ.shape) == 2 and val_targ.shape[1] != 1:\n",
        "            val_targ = np.argmax(val_targ, -1)\n",
        "\n",
        "        _val_f1 = f1_score(val_targ, val_predict, average='macro')\n",
        "        _val_recall = recall_score(val_targ, val_predict, average='macro')\n",
        "        _val_precision = precision_score(val_targ, val_predict, average='macro')\n",
        "\n",
        "        logs['val_f1'] = _val_f1\n",
        "        logs['val_recall'] = _val_recall\n",
        "        logs['val_precision'] = _val_precision\n",
        "        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" % (_val_f1, _val_precision, _val_recall))\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYw7D4btD7u0"
      },
      "source": [
        "### Create f1-score metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xRkdbZUMDwfZ"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall_keras = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall_keras\n",
        "\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision_keras = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision_keras\n",
        "\n",
        "\n",
        "def specificity(y_true, y_pred):\n",
        "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
        "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
        "    return tn / (tn + fp + K.epsilon())\n",
        "\n",
        "\n",
        "def negative_predictive_value(y_true, y_pred):\n",
        "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
        "    fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
        "    return tn / (tn + fn + K.epsilon())\n",
        "\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    return 2 * ((p * r) / (p + r + K.epsilon()))\n",
        "\n",
        "\n",
        "def fbeta(y_true, y_pred, beta=2):\n",
        "    y_pred = K.clip(y_pred, 0, 1)\n",
        "\n",
        "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n",
        "    fp = K.sum(K.round(K.clip(y_pred - y_true, 0, 1)), axis=1)\n",
        "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)), axis=1)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    num = (1 + beta ** 2) * (p * r)\n",
        "    den = (beta ** 2 * p + r + K.epsilon())\n",
        "    return K.mean(num / den)\n",
        "\n",
        "\n",
        "def matthews_correlation_coefficient(y_true, y_pred):\n",
        "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
        "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
        "    fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
        "\n",
        "    num = tp * tn - fp * fn\n",
        "    den = (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\n",
        "    return num / K.sqrt(den + K.epsilon())\n",
        "\n",
        "\n",
        "def equal_error_rate(y_true, y_pred):\n",
        "    n_imp = tf.count_nonzero(tf.equal(y_true, 0), dtype=tf.float32) + tf.constant(K.epsilon())\n",
        "    n_gen = tf.count_nonzero(tf.equal(y_true, 1), dtype=tf.float32) + tf.constant(K.epsilon())\n",
        "\n",
        "    scores_imp = tf.boolean_mask(y_pred, tf.equal(y_true, 0))\n",
        "    scores_gen = tf.boolean_mask(y_pred, tf.equal(y_true, 1))\n",
        "\n",
        "    loop_vars = (tf.constant(0.0), tf.constant(1.0), tf.constant(0.0))\n",
        "    cond = lambda t, fpr, fnr: tf.greater_equal(fpr, fnr)\n",
        "    body = lambda t, fpr, fnr: (\n",
        "        t + 0.001,\n",
        "        tf.divide(tf.count_nonzero(tf.greater_equal(scores_imp, t), dtype=tf.float32), n_imp),\n",
        "        tf.divide(tf.count_nonzero(tf.less(scores_gen, t), dtype=tf.float32), n_gen)\n",
        "    )\n",
        "    t, fpr, fnr = tf.while_loop(cond, body, loop_vars, back_prop=False)\n",
        "    eer = (fpr + fnr) / 2\n",
        "\n",
        "    return eer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_auGh-iwnQy"
      },
      "source": [
        "### Warmup and Cosine Learning rate eecay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exSDHqEGwwcf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import (\n",
        "    Callback,\n",
        "    LearningRateScheduler,\n",
        "    TensorBoard\n",
        ")\n",
        "\n",
        "\n",
        "def cosine_decay_with_warmup(global_step,\n",
        "                             learning_rate_base,\n",
        "                             total_steps,\n",
        "                             warmup_learning_rate=0.0,\n",
        "                             warmup_steps=0,\n",
        "                             hold_base_rate_steps=0):\n",
        "    \"\"\"Cosine decay schedule with warm up period.\n",
        "\n",
        "    Cosine annealing learning rate as described in:\n",
        "      Loshchilov and Hutter, SGDR: Stochastic Gradient Descent with Warm Restarts.\n",
        "      ICLR 2017. https://arxiv.org/abs/1608.03983\n",
        "    In this schedule, the learning rate grows linearly from warmup_learning_rate\n",
        "    to learning_rate_base for warmup_steps, then transitions to a cosine decay\n",
        "    schedule.\n",
        "\n",
        "    Arguments:\n",
        "        global_step {int} -- global step.\n",
        "        learning_rate_base {float} -- base learning rate.\n",
        "        total_steps {int} -- total number of training steps.\n",
        "\n",
        "    Keyword Arguments:\n",
        "        warmup_learning_rate {float} -- initial learning rate for warm up. (default: {0.0})\n",
        "        warmup_steps {int} -- number of warmup steps. (default: {0})\n",
        "        hold_base_rate_steps {int} -- Optional number of steps to hold base learning rate\n",
        "                                    before decaying. (default: {0})\n",
        "    Returns:\n",
        "      a float representing learning rate.\n",
        "\n",
        "    Raises:\n",
        "      ValueError: if warmup_learning_rate is larger than learning_rate_base,\n",
        "        or if warmup_steps is larger than total_steps.\n",
        "    \"\"\"\n",
        "\n",
        "    if total_steps < warmup_steps:\n",
        "        raise ValueError('total_steps must be larger or equal to '\n",
        "                         'warmup_steps.')\n",
        "    learning_rate = 0.5 * learning_rate_base * (1 + np.cos(\n",
        "        np.pi *\n",
        "        (global_step - warmup_steps - hold_base_rate_steps\n",
        "         ) / float(total_steps - warmup_steps - hold_base_rate_steps)))\n",
        "    if hold_base_rate_steps > 0:\n",
        "        learning_rate = np.where(global_step > warmup_steps + hold_base_rate_steps,\n",
        "                                 learning_rate, learning_rate_base)\n",
        "    if warmup_steps > 0:\n",
        "        if learning_rate_base < warmup_learning_rate:\n",
        "            raise ValueError('learning_rate_base must be larger or equal to '\n",
        "                             'warmup_learning_rate.')\n",
        "        slope = (learning_rate_base - warmup_learning_rate) / warmup_steps\n",
        "        warmup_rate = slope * global_step + warmup_learning_rate\n",
        "        learning_rate = np.where(global_step < warmup_steps, warmup_rate,\n",
        "                                 learning_rate)\n",
        "    return np.where(global_step > total_steps, 0.0, learning_rate)\n",
        "\n",
        "\n",
        "class WarmUpCosineDecayScheduler(keras.callbacks.Callback):\n",
        "    \"\"\"Cosine decay with warmup learning rate scheduler\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 learning_rate_base,\n",
        "                 total_steps,\n",
        "                 global_step_init=0,\n",
        "                 warmup_learning_rate=0.0,\n",
        "                 warmup_steps=0,\n",
        "                 hold_base_rate_steps=0,\n",
        "                 verbose=0):\n",
        "        \"\"\"Constructor for cosine decay with warmup learning rate scheduler.\n",
        "\n",
        "    Arguments:\n",
        "        learning_rate_base {float} -- base learning rate.\n",
        "        total_steps {int} -- total number of training steps.\n",
        "\n",
        "    Keyword Arguments:\n",
        "        global_step_init {int} -- initial global step, e.g. from previous checkpoint.\n",
        "        warmup_learning_rate {float} -- initial learning rate for warm up. (default: {0.0})\n",
        "        warmup_steps {int} -- number of warmup steps. (default: {0})\n",
        "        hold_base_rate_steps {int} -- Optional number of steps to hold base learning rate\n",
        "                                    before decaying. (default: {0})\n",
        "        verbose {int} -- 0: quiet, 1: update messages. (default: {0})\n",
        "        \"\"\"\n",
        "\n",
        "        super(WarmUpCosineDecayScheduler, self).__init__()\n",
        "        self.learning_rate_base = learning_rate_base\n",
        "        self.total_steps = total_steps\n",
        "        self.global_step = global_step_init\n",
        "        self.warmup_learning_rate = warmup_learning_rate\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.hold_base_rate_steps = hold_base_rate_steps\n",
        "        self.verbose = verbose\n",
        "        self.learning_rates = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.global_step = self.global_step + 1\n",
        "        lr = K.get_value(self.model.optimizer.lr)\n",
        "        self.learning_rates.append(lr)\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        lr = cosine_decay_with_warmup(global_step=self.global_step,\n",
        "                                      learning_rate_base=self.learning_rate_base,\n",
        "                                      total_steps=self.total_steps,\n",
        "                                      warmup_learning_rate=self.warmup_learning_rate,\n",
        "                                      warmup_steps=self.warmup_steps,\n",
        "                                      hold_base_rate_steps=self.hold_base_rate_steps)\n",
        "        K.set_value(self.model.optimizer.lr, lr)\n",
        "        if self.verbose > 0:\n",
        "            print('\\nBatch %05d: setting learning '\n",
        "                  'rate to %s.' % (self.global_step + 1, lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L79dAetEEJ7x"
      },
      "source": [
        "## Transfer learning with Xception model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjYNlvR4EZPA"
      },
      "source": [
        "### Create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AlbGI6LKEbjo"
      },
      "outputs": [],
      "source": [
        "xception_model_input = tf.keras.applications.xception.Xception(weights='imagenet', include_top=False, input_shape=(224, 224,3), classes=4)\n",
        "\n",
        "for layers in xception_model_input.layers[:125]:\n",
        "    layers.trainable=False\n",
        "\n",
        "\n",
        "xception_model = tf.keras.layers.Flatten()(xception_model_input.output)\n",
        "xception_model = tf.keras.layers.Dropout(0.5)(xception_model)\n",
        "xception_model = tf.keras.layers.Dense(4, activation='softmax')(xception_model)\n",
        "xception_model_final = tf.keras.Model(inputs=xception_model_input.input, outputs=xception_model)\n",
        "\n",
        "def get_lr_metric(optimizer):\n",
        "    def lr(y_true, y_pred):\n",
        "        return optimizer._decayed_lr(tf.float32) # I use ._decayed_lr method instead of .lr\n",
        "    return lr\n",
        "# learning_rate = tf.keras.optimizers.schedules.CosineDecayRestarts(initial_learning_rate=1e-3, first_decay_steps=6, t_mul=2.0, m_mul=1.0, alpha=1e-10, name=None)\n",
        "optimizer = tf.keras.optimizers.Adam(lr=1e-4)\n",
        "lr_metric = get_lr_metric(optimizer)\n",
        "xception_model_final.compile(loss = 'categorical_crossentropy', optimizer= optimizer, metrics=['accuracy', f1, lr_metric])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "muKGbmej_n8m"
      },
      "outputs": [],
      "source": [
        "xception_model_final.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y6UP6T5Feyw"
      },
      "source": [
        "### Create checkpoint callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tDLcdTPXFi5j"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  os.mkdir('checkpoint')\n",
        "except:\n",
        "  pass\n",
        "xception_filepath = 'checkpoint/xception125-no-dense_batch16-do50-lr_const'+'.h5'\n",
        "xception_checkpoint = tf.keras.callbacks.ModelCheckpoint(xception_filepath, monitor='val_f1', \n",
        "                                                 mode='max', verbose=1,\n",
        "                                                 save_best_only=True,\n",
        "                                                 save_weights_only=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZicmbhawEK4e",
        "outputId": "a919d929-badc-4674-e4ea-53f47fabd103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.7144 - f1: 0.6983 - lr: 1.0000e-04\n",
            "Epoch 1: val_f1 improved from -inf to 0.80143, saving model to checkpoint/xception125-no-dense_batch16-do50-lr_const.h5\n",
            "57/57 [==============================] - 47s 736ms/step - loss: 0.6929 - accuracy: 0.7144 - f1: 0.6983 - lr: 1.0000e-04 - val_loss: 0.4727 - val_accuracy: 0.8115 - val_f1: 0.8014 - val_lr: 1.0000e-04\n",
            "Epoch 2/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4008 - accuracy: 0.8533 - f1: 0.8614 - lr: 1.0000e-04\n",
            "Epoch 2: val_f1 improved from 0.80143 to 0.88873, saving model to checkpoint/xception125-no-dense_batch16-do50-lr_const.h5\n",
            "57/57 [==============================] - 41s 723ms/step - loss: 0.4008 - accuracy: 0.8533 - f1: 0.8614 - lr: 1.0000e-04 - val_loss: 0.3557 - val_accuracy: 0.8846 - val_f1: 0.8887 - val_lr: 1.0000e-04\n",
            "Epoch 3/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.2858 - accuracy: 0.9011 - f1: 0.8934 - lr: 1.0000e-04\n",
            "Epoch 3: val_f1 improved from 0.88873 to 0.89777, saving model to checkpoint/xception125-no-dense_batch16-do50-lr_const.h5\n",
            "57/57 [==============================] - 41s 718ms/step - loss: 0.2858 - accuracy: 0.9011 - f1: 0.8934 - lr: 1.0000e-04 - val_loss: 0.3266 - val_accuracy: 0.8962 - val_f1: 0.8978 - val_lr: 1.0000e-04\n",
            "Epoch 4/200\n",
            "25/57 [============>.................] - ETA: 17s - loss: 0.2234 - accuracy: 0.9175 - f1: 0.9175 - lr: 1.0000e-04"
          ]
        }
      ],
      "source": [
        "number_of_epochs = 200\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_f1', mode='max', factor=0.3, patience=3, min_lr=1e-7)\n",
        "\n",
        "xception_callbacklist = [xception_checkpoint]\n",
        "xception_history = xception_model_final.fit(train_data_multi, epochs = number_of_epochs ,validation_data = test_data_multi, callbacks=xception_callbacklist,verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtxrnVhOtcUk"
      },
      "source": [
        "## Transfer learning with VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onQ9B0Aatzvn",
        "outputId": "a321147a-c049-4287-e19f-5502b19e8e35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "vgg16_model_input = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, pooling='max', input_shape=(224, 224,3), classes=4)\n",
        "\n",
        "for layers in vgg16_model_input.layers:\n",
        "    layers.trainable=False\n",
        "\n",
        "\n",
        "vgg16_model = tf.keras.layers.Flatten()(vgg16_model_input.output)\n",
        "# vgg16_model = tf.keras.layers.Dropout(0.2)(vgg16_model)\n",
        "vgg16_model = tf.keras.layers.Dense(4, activation='softmax')(vgg16_model)\n",
        "vgg16_model_final = tf.keras.Model(inputs=vgg16_model_input.input, outputs=vgg16_model)\n",
        "\n",
        "def get_lr_metric(optimizer):\n",
        "    def lr(y_true, y_pred):\n",
        "        return optimizer._decayed_lr(tf.float32) # I use ._decayed_lr method instead of .lr\n",
        "    return lr\n",
        "# learning_rate = tf.keras.optimizers.schedules.CosineDecayRestarts(initial_learning_rate=1e-3, first_decay_steps=6, t_mul=2.0, m_mul=1.0, alpha=1e-10, name=None)\n",
        "optimizer = tf.keras.optimizers.Adam(lr=5e-5, clipnorm=1.)\n",
        "# lr_metric = get_lr_metric(optimizer)\n",
        "vgg16_model_final.compile(loss = 'categorical_crossentropy', optimizer= optimizer, metrics=['accuracy', f1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDn6d7WmM8zt"
      },
      "source": [
        "## Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DHmCO-uLEH0z",
        "outputId": "3888b6f1-c41a-4310-a6e4-3c22027b4f82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.7110 - accuracy: 0.3800 - f1: 0.3303\n",
            "Epoch 1: val_f1 improved from -inf to 0.34765, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 370s 6s/step - loss: 1.7110 - accuracy: 0.3800 - f1: 0.3303 - val_loss: 1.5421 - val_accuracy: 0.3846 - val_f1: 0.3477\n",
            "Epoch 2/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.4070 - accuracy: 0.4033 - f1: 0.2876\n",
            "Epoch 2: val_f1 did not improve from 0.34765\n",
            "57/57 [==============================] - 43s 751ms/step - loss: 1.4070 - accuracy: 0.4033 - f1: 0.2876 - val_loss: 1.3466 - val_accuracy: 0.3846 - val_f1: 0.2517\n",
            "Epoch 3/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.2711 - accuracy: 0.4222 - f1: 0.2785\n",
            "Epoch 3: val_f1 did not improve from 0.34765\n",
            "57/57 [==============================] - 43s 750ms/step - loss: 1.2711 - accuracy: 0.4222 - f1: 0.2785 - val_loss: 1.2294 - val_accuracy: 0.4462 - val_f1: 0.2797\n",
            "Epoch 4/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.2284 - accuracy: 0.4356 - f1: 0.2864\n",
            "Epoch 4: val_f1 did not improve from 0.34765\n",
            "57/57 [==============================] - 43s 751ms/step - loss: 1.2284 - accuracy: 0.4356 - f1: 0.2864 - val_loss: 1.2188 - val_accuracy: 0.4654 - val_f1: 0.2832\n",
            "Epoch 5/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.1700 - accuracy: 0.4700 - f1: 0.2950\n",
            "Epoch 5: val_f1 did not improve from 0.34765\n",
            "57/57 [==============================] - 43s 750ms/step - loss: 1.1700 - accuracy: 0.4700 - f1: 0.2950 - val_loss: 1.1567 - val_accuracy: 0.5000 - val_f1: 0.3336\n",
            "Epoch 6/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.1233 - accuracy: 0.4978 - f1: 0.3311\n",
            "Epoch 6: val_f1 improved from 0.34765 to 0.34905, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 44s 770ms/step - loss: 1.1233 - accuracy: 0.4978 - f1: 0.3311 - val_loss: 1.1162 - val_accuracy: 0.4962 - val_f1: 0.3490\n",
            "Epoch 7/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.0860 - accuracy: 0.5367 - f1: 0.3870\n",
            "Epoch 7: val_f1 improved from 0.34905 to 0.40763, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 43s 761ms/step - loss: 1.0860 - accuracy: 0.5367 - f1: 0.3870 - val_loss: 1.0682 - val_accuracy: 0.5462 - val_f1: 0.4076\n",
            "Epoch 8/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.0526 - accuracy: 0.5522 - f1: 0.4028\n",
            "Epoch 8: val_f1 improved from 0.40763 to 0.43462, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 43s 755ms/step - loss: 1.0526 - accuracy: 0.5522 - f1: 0.4028 - val_loss: 1.0282 - val_accuracy: 0.6077 - val_f1: 0.4346\n",
            "Epoch 9/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.0244 - accuracy: 0.5700 - f1: 0.4466\n",
            "Epoch 9: val_f1 did not improve from 0.43462\n",
            "57/57 [==============================] - 42s 743ms/step - loss: 1.0244 - accuracy: 0.5700 - f1: 0.4466 - val_loss: 1.0298 - val_accuracy: 0.5538 - val_f1: 0.4215\n",
            "Epoch 10/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.9831 - accuracy: 0.5867 - f1: 0.4705\n",
            "Epoch 10: val_f1 improved from 0.43462 to 0.46133, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 43s 755ms/step - loss: 0.9831 - accuracy: 0.5867 - f1: 0.4705 - val_loss: 1.0127 - val_accuracy: 0.5923 - val_f1: 0.4613\n",
            "Epoch 11/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.9677 - accuracy: 0.6178 - f1: 0.4688\n",
            "Epoch 11: val_f1 improved from 0.46133 to 0.49589, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 43s 753ms/step - loss: 0.9677 - accuracy: 0.6178 - f1: 0.4688 - val_loss: 0.9407 - val_accuracy: 0.6231 - val_f1: 0.4959\n",
            "Epoch 12/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.9232 - accuracy: 0.6411 - f1: 0.5134\n",
            "Epoch 12: val_f1 did not improve from 0.49589\n",
            "57/57 [==============================] - 42s 754ms/step - loss: 0.9232 - accuracy: 0.6411 - f1: 0.5134 - val_loss: 0.9576 - val_accuracy: 0.6038 - val_f1: 0.4911\n",
            "Epoch 13/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.9046 - accuracy: 0.6467 - f1: 0.5171\n",
            "Epoch 13: val_f1 improved from 0.49589 to 0.52445, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 43s 750ms/step - loss: 0.9046 - accuracy: 0.6467 - f1: 0.5171 - val_loss: 0.9157 - val_accuracy: 0.6500 - val_f1: 0.5245\n",
            "Epoch 14/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.8943 - accuracy: 0.6367 - f1: 0.5484\n",
            "Epoch 14: val_f1 improved from 0.52445 to 0.54003, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 43s 755ms/step - loss: 0.8943 - accuracy: 0.6367 - f1: 0.5484 - val_loss: 0.9357 - val_accuracy: 0.6038 - val_f1: 0.5400\n",
            "Epoch 15/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.8638 - accuracy: 0.6478 - f1: 0.5692\n",
            "Epoch 15: val_f1 improved from 0.54003 to 0.54575, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 43s 749ms/step - loss: 0.8638 - accuracy: 0.6478 - f1: 0.5692 - val_loss: 0.9197 - val_accuracy: 0.6192 - val_f1: 0.5457\n",
            "Epoch 16/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.8285 - accuracy: 0.6767 - f1: 0.5873\n",
            "Epoch 16: val_f1 improved from 0.54575 to 0.56527, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 43s 758ms/step - loss: 0.8285 - accuracy: 0.6767 - f1: 0.5873 - val_loss: 0.8861 - val_accuracy: 0.6385 - val_f1: 0.5653\n",
            "Epoch 17/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.8224 - accuracy: 0.6867 - f1: 0.5956\n",
            "Epoch 17: val_f1 improved from 0.56527 to 0.60241, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 44s 774ms/step - loss: 0.8224 - accuracy: 0.6867 - f1: 0.5956 - val_loss: 0.8380 - val_accuracy: 0.6769 - val_f1: 0.6024\n",
            "Epoch 18/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.8043 - accuracy: 0.7089 - f1: 0.6046\n",
            "Epoch 18: val_f1 improved from 0.60241 to 0.62308, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 43s 764ms/step - loss: 0.8043 - accuracy: 0.7089 - f1: 0.6046 - val_loss: 0.8239 - val_accuracy: 0.6577 - val_f1: 0.6231\n",
            "Epoch 19/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.8068 - accuracy: 0.6833 - f1: 0.5875\n",
            "Epoch 19: val_f1 did not improve from 0.62308\n",
            "57/57 [==============================] - 42s 735ms/step - loss: 0.8068 - accuracy: 0.6833 - f1: 0.5875 - val_loss: 0.8245 - val_accuracy: 0.7038 - val_f1: 0.6008\n",
            "Epoch 20/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.7868 - accuracy: 0.6956 - f1: 0.6269\n",
            "Epoch 20: val_f1 improved from 0.62308 to 0.62622, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 43s 762ms/step - loss: 0.7868 - accuracy: 0.6956 - f1: 0.6269 - val_loss: 0.8357 - val_accuracy: 0.6731 - val_f1: 0.6262\n",
            "Epoch 21/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.7754 - accuracy: 0.7089 - f1: 0.6376\n",
            "Epoch 21: val_f1 did not improve from 0.62622\n",
            "57/57 [==============================] - 43s 749ms/step - loss: 0.7754 - accuracy: 0.7089 - f1: 0.6376 - val_loss: 0.7804 - val_accuracy: 0.7385 - val_f1: 0.6025\n",
            "Epoch 22/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.7482 - accuracy: 0.7267 - f1: 0.6571\n",
            "Epoch 22: val_f1 improved from 0.62622 to 0.64223, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 43s 755ms/step - loss: 0.7482 - accuracy: 0.7267 - f1: 0.6571 - val_loss: 0.7989 - val_accuracy: 0.6846 - val_f1: 0.6422\n",
            "Epoch 23/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.7313 - accuracy: 0.7111 - f1: 0.6647\n",
            "Epoch 23: val_f1 improved from 0.64223 to 0.67338, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 44s 771ms/step - loss: 0.7313 - accuracy: 0.7111 - f1: 0.6647 - val_loss: 0.7815 - val_accuracy: 0.7077 - val_f1: 0.6734\n",
            "Epoch 24/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.7221 - accuracy: 0.7333 - f1: 0.6721\n",
            "Epoch 24: val_f1 did not improve from 0.67338\n",
            "57/57 [==============================] - 43s 756ms/step - loss: 0.7221 - accuracy: 0.7333 - f1: 0.6721 - val_loss: 0.7692 - val_accuracy: 0.7038 - val_f1: 0.6571\n",
            "Epoch 25/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.7142 - accuracy: 0.7389 - f1: 0.6748\n",
            "Epoch 25: val_f1 did not improve from 0.67338\n",
            "57/57 [==============================] - 43s 755ms/step - loss: 0.7142 - accuracy: 0.7389 - f1: 0.6748 - val_loss: 0.7913 - val_accuracy: 0.6654 - val_f1: 0.6249\n",
            "Epoch 26/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.7025 - accuracy: 0.7500 - f1: 0.6687\n",
            "Epoch 26: val_f1 did not improve from 0.67338\n",
            "57/57 [==============================] - 42s 747ms/step - loss: 0.7025 - accuracy: 0.7500 - f1: 0.6687 - val_loss: 0.7662 - val_accuracy: 0.7077 - val_f1: 0.6560\n",
            "Epoch 27/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.7047 - accuracy: 0.7400 - f1: 0.6811\n",
            "Epoch 27: val_f1 did not improve from 0.67338\n",
            "57/57 [==============================] - 43s 756ms/step - loss: 0.7047 - accuracy: 0.7400 - f1: 0.6811 - val_loss: 0.7295 - val_accuracy: 0.7000 - val_f1: 0.6688\n",
            "Epoch 28/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.6769 - accuracy: 0.7622 - f1: 0.6936\n",
            "Epoch 28: val_f1 did not improve from 0.67338\n",
            "57/57 [==============================] - 43s 753ms/step - loss: 0.6769 - accuracy: 0.7622 - f1: 0.6936 - val_loss: 0.7366 - val_accuracy: 0.7077 - val_f1: 0.6666\n",
            "Epoch 29/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.6684 - accuracy: 0.7544 - f1: 0.7031\n",
            "Epoch 29: val_f1 did not improve from 0.67338\n",
            "57/57 [==============================] - 43s 755ms/step - loss: 0.6684 - accuracy: 0.7544 - f1: 0.7031 - val_loss: 0.7184 - val_accuracy: 0.7423 - val_f1: 0.6725\n",
            "Epoch 30/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.6672 - accuracy: 0.7489 - f1: 0.6948\n",
            "Epoch 30: val_f1 did not improve from 0.67338\n",
            "57/57 [==============================] - 42s 738ms/step - loss: 0.6672 - accuracy: 0.7489 - f1: 0.6948 - val_loss: 0.7455 - val_accuracy: 0.7077 - val_f1: 0.6578\n",
            "Epoch 31/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.6745 - accuracy: 0.7478 - f1: 0.6920\n",
            "Epoch 31: val_f1 improved from 0.67338 to 0.67768, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 43s 764ms/step - loss: 0.6745 - accuracy: 0.7478 - f1: 0.6920 - val_loss: 0.7211 - val_accuracy: 0.7154 - val_f1: 0.6777\n",
            "Epoch 32/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.6491 - accuracy: 0.7656 - f1: 0.7241\n",
            "Epoch 32: val_f1 improved from 0.67768 to 0.72132, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 44s 769ms/step - loss: 0.6491 - accuracy: 0.7656 - f1: 0.7241 - val_loss: 0.7126 - val_accuracy: 0.7308 - val_f1: 0.7213\n",
            "Epoch 33/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.6428 - accuracy: 0.7700 - f1: 0.7155\n",
            "Epoch 33: val_f1 did not improve from 0.72132\n",
            "57/57 [==============================] - 43s 752ms/step - loss: 0.6428 - accuracy: 0.7700 - f1: 0.7155 - val_loss: 0.6819 - val_accuracy: 0.7538 - val_f1: 0.7172\n",
            "Epoch 34/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.6504 - accuracy: 0.7467 - f1: 0.7128\n",
            "Epoch 34: val_f1 did not improve from 0.72132\n",
            "57/57 [==============================] - 42s 748ms/step - loss: 0.6504 - accuracy: 0.7467 - f1: 0.7128 - val_loss: 0.6689 - val_accuracy: 0.7269 - val_f1: 0.7200\n",
            "Epoch 35/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.6291 - accuracy: 0.7900 - f1: 0.7289\n",
            "Epoch 35: val_f1 did not improve from 0.72132\n",
            "57/57 [==============================] - 43s 758ms/step - loss: 0.6291 - accuracy: 0.7900 - f1: 0.7289 - val_loss: 0.6905 - val_accuracy: 0.7462 - val_f1: 0.7175\n",
            "Epoch 36/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.6383 - accuracy: 0.7456 - f1: 0.7227\n",
            "Epoch 36: val_f1 did not improve from 0.72132\n",
            "57/57 [==============================] - 42s 745ms/step - loss: 0.6383 - accuracy: 0.7456 - f1: 0.7227 - val_loss: 0.6791 - val_accuracy: 0.7500 - val_f1: 0.7181\n",
            "Epoch 37/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.6200 - accuracy: 0.7656 - f1: 0.7221\n",
            "Epoch 37: val_f1 did not improve from 0.72132\n",
            "57/57 [==============================] - 43s 756ms/step - loss: 0.6200 - accuracy: 0.7656 - f1: 0.7221 - val_loss: 0.6691 - val_accuracy: 0.7308 - val_f1: 0.7103\n",
            "Epoch 38/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.6122 - accuracy: 0.7656 - f1: 0.7443\n",
            "Epoch 38: val_f1 did not improve from 0.72132\n",
            "57/57 [==============================] - 43s 752ms/step - loss: 0.6122 - accuracy: 0.7656 - f1: 0.7443 - val_loss: 0.6717 - val_accuracy: 0.7308 - val_f1: 0.7155\n",
            "Epoch 39/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.6152 - accuracy: 0.7722 - f1: 0.7416\n",
            "Epoch 39: val_f1 did not improve from 0.72132\n",
            "57/57 [==============================] - 42s 743ms/step - loss: 0.6152 - accuracy: 0.7722 - f1: 0.7416 - val_loss: 0.6607 - val_accuracy: 0.7654 - val_f1: 0.7164\n",
            "Epoch 40/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.6039 - accuracy: 0.7756 - f1: 0.7512\n",
            "Epoch 40: val_f1 did not improve from 0.72132\n",
            "57/57 [==============================] - 43s 760ms/step - loss: 0.6039 - accuracy: 0.7756 - f1: 0.7512 - val_loss: 0.6656 - val_accuracy: 0.7692 - val_f1: 0.7112\n",
            "Epoch 41/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5825 - accuracy: 0.7800 - f1: 0.7636\n",
            "Epoch 41: val_f1 improved from 0.72132 to 0.75995, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 44s 768ms/step - loss: 0.5825 - accuracy: 0.7800 - f1: 0.7636 - val_loss: 0.6373 - val_accuracy: 0.7808 - val_f1: 0.7600\n",
            "Epoch 42/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.6015 - accuracy: 0.7522 - f1: 0.7258\n",
            "Epoch 42: val_f1 did not improve from 0.75995\n",
            "57/57 [==============================] - 43s 747ms/step - loss: 0.6015 - accuracy: 0.7522 - f1: 0.7258 - val_loss: 0.6942 - val_accuracy: 0.7115 - val_f1: 0.6990\n",
            "Epoch 43/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5986 - accuracy: 0.7689 - f1: 0.7520\n",
            "Epoch 43: val_f1 did not improve from 0.75995\n",
            "57/57 [==============================] - 43s 758ms/step - loss: 0.5986 - accuracy: 0.7689 - f1: 0.7520 - val_loss: 0.6266 - val_accuracy: 0.7692 - val_f1: 0.7340\n",
            "Epoch 44/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5825 - accuracy: 0.7667 - f1: 0.7623\n",
            "Epoch 44: val_f1 did not improve from 0.75995\n",
            "57/57 [==============================] - 43s 746ms/step - loss: 0.5825 - accuracy: 0.7667 - f1: 0.7623 - val_loss: 0.6201 - val_accuracy: 0.7654 - val_f1: 0.7396\n",
            "Epoch 45/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5862 - accuracy: 0.7689 - f1: 0.7506\n",
            "Epoch 45: val_f1 did not improve from 0.75995\n",
            "57/57 [==============================] - 43s 761ms/step - loss: 0.5862 - accuracy: 0.7689 - f1: 0.7506 - val_loss: 0.6439 - val_accuracy: 0.7577 - val_f1: 0.7231\n",
            "Epoch 46/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5960 - accuracy: 0.7667 - f1: 0.7363\n",
            "Epoch 46: val_f1 did not improve from 0.75995\n",
            "57/57 [==============================] - 43s 757ms/step - loss: 0.5960 - accuracy: 0.7667 - f1: 0.7363 - val_loss: 0.6359 - val_accuracy: 0.7538 - val_f1: 0.7250\n",
            "Epoch 47/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5868 - accuracy: 0.7778 - f1: 0.7561\n",
            "Epoch 47: val_f1 did not improve from 0.75995\n",
            "57/57 [==============================] - 43s 760ms/step - loss: 0.5868 - accuracy: 0.7778 - f1: 0.7561 - val_loss: 0.6502 - val_accuracy: 0.7346 - val_f1: 0.7252\n",
            "Epoch 48/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5606 - accuracy: 0.7967 - f1: 0.7683\n",
            "Epoch 48: val_f1 did not improve from 0.75995\n",
            "57/57 [==============================] - 43s 752ms/step - loss: 0.5606 - accuracy: 0.7967 - f1: 0.7683 - val_loss: 0.6155 - val_accuracy: 0.7615 - val_f1: 0.7555\n",
            "Epoch 49/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5762 - accuracy: 0.7744 - f1: 0.7497\n",
            "Epoch 49: val_f1 did not improve from 0.75995\n",
            "57/57 [==============================] - 43s 759ms/step - loss: 0.5762 - accuracy: 0.7744 - f1: 0.7497 - val_loss: 0.6071 - val_accuracy: 0.7731 - val_f1: 0.7416\n",
            "Epoch 50/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5413 - accuracy: 0.8033 - f1: 0.7793\n",
            "Epoch 50: val_f1 improved from 0.75995 to 0.76322, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 43s 761ms/step - loss: 0.5413 - accuracy: 0.8033 - f1: 0.7793 - val_loss: 0.6104 - val_accuracy: 0.7846 - val_f1: 0.7632\n",
            "Epoch 51/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5509 - accuracy: 0.7822 - f1: 0.7709\n",
            "Epoch 51: val_f1 improved from 0.76322 to 0.76519, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 44s 784ms/step - loss: 0.5509 - accuracy: 0.7822 - f1: 0.7709 - val_loss: 0.5938 - val_accuracy: 0.8038 - val_f1: 0.7652\n",
            "Epoch 52/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5742 - accuracy: 0.7711 - f1: 0.7555\n",
            "Epoch 52: val_f1 did not improve from 0.76519\n",
            "57/57 [==============================] - 43s 751ms/step - loss: 0.5742 - accuracy: 0.7711 - f1: 0.7555 - val_loss: 0.6316 - val_accuracy: 0.7577 - val_f1: 0.7233\n",
            "Epoch 53/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5473 - accuracy: 0.7922 - f1: 0.7639\n",
            "Epoch 53: val_f1 did not improve from 0.76519\n",
            "57/57 [==============================] - 43s 763ms/step - loss: 0.5473 - accuracy: 0.7922 - f1: 0.7639 - val_loss: 0.5982 - val_accuracy: 0.7577 - val_f1: 0.7431\n",
            "Epoch 54/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5460 - accuracy: 0.7856 - f1: 0.7682\n",
            "Epoch 54: val_f1 improved from 0.76519 to 0.77062, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 43s 770ms/step - loss: 0.5460 - accuracy: 0.7856 - f1: 0.7682 - val_loss: 0.6154 - val_accuracy: 0.7654 - val_f1: 0.7706\n",
            "Epoch 55/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5272 - accuracy: 0.8167 - f1: 0.7901\n",
            "Epoch 55: val_f1 improved from 0.77062 to 0.78051, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 44s 775ms/step - loss: 0.5272 - accuracy: 0.8167 - f1: 0.7901 - val_loss: 0.5926 - val_accuracy: 0.7654 - val_f1: 0.7805\n",
            "Epoch 56/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.8044 - f1: 0.7850\n",
            "Epoch 56: val_f1 did not improve from 0.78051\n",
            "57/57 [==============================] - 43s 762ms/step - loss: 0.5345 - accuracy: 0.8044 - f1: 0.7850 - val_loss: 0.6145 - val_accuracy: 0.7538 - val_f1: 0.7303\n",
            "Epoch 57/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5123 - accuracy: 0.8144 - f1: 0.8031\n",
            "Epoch 57: val_f1 did not improve from 0.78051\n",
            "57/57 [==============================] - 43s 772ms/step - loss: 0.5123 - accuracy: 0.8144 - f1: 0.8031 - val_loss: 0.5893 - val_accuracy: 0.7692 - val_f1: 0.7186\n",
            "Epoch 58/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5319 - accuracy: 0.8078 - f1: 0.7837\n",
            "Epoch 58: val_f1 did not improve from 0.78051\n",
            "57/57 [==============================] - 43s 757ms/step - loss: 0.5319 - accuracy: 0.8078 - f1: 0.7837 - val_loss: 0.6052 - val_accuracy: 0.7692 - val_f1: 0.7349\n",
            "Epoch 59/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5422 - accuracy: 0.7933 - f1: 0.7705\n",
            "Epoch 59: val_f1 did not improve from 0.78051\n",
            "57/57 [==============================] - 44s 767ms/step - loss: 0.5422 - accuracy: 0.7933 - f1: 0.7705 - val_loss: 0.5886 - val_accuracy: 0.7808 - val_f1: 0.7671\n",
            "Epoch 60/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5219 - accuracy: 0.8100 - f1: 0.7884\n",
            "Epoch 60: val_f1 improved from 0.78051 to 0.78100, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 44s 767ms/step - loss: 0.5219 - accuracy: 0.8100 - f1: 0.7884 - val_loss: 0.5454 - val_accuracy: 0.7885 - val_f1: 0.7810\n",
            "Epoch 61/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5156 - accuracy: 0.8000 - f1: 0.7808\n",
            "Epoch 61: val_f1 did not improve from 0.78100\n",
            "57/57 [==============================] - 43s 761ms/step - loss: 0.5156 - accuracy: 0.8000 - f1: 0.7808 - val_loss: 0.5984 - val_accuracy: 0.7654 - val_f1: 0.7659\n",
            "Epoch 62/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5225 - accuracy: 0.7989 - f1: 0.7913\n",
            "Epoch 62: val_f1 did not improve from 0.78100\n",
            "57/57 [==============================] - 43s 764ms/step - loss: 0.5225 - accuracy: 0.7989 - f1: 0.7913 - val_loss: 0.5799 - val_accuracy: 0.7731 - val_f1: 0.7316\n",
            "Epoch 63/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5146 - accuracy: 0.8056 - f1: 0.7886\n",
            "Epoch 63: val_f1 did not improve from 0.78100\n",
            "57/57 [==============================] - 43s 757ms/step - loss: 0.5146 - accuracy: 0.8056 - f1: 0.7886 - val_loss: 0.5695 - val_accuracy: 0.7808 - val_f1: 0.7632\n",
            "Epoch 64/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5111 - accuracy: 0.8044 - f1: 0.7996\n",
            "Epoch 64: val_f1 improved from 0.78100 to 0.79030, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 43s 752ms/step - loss: 0.5111 - accuracy: 0.8044 - f1: 0.7996 - val_loss: 0.5696 - val_accuracy: 0.7808 - val_f1: 0.7903\n",
            "Epoch 65/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5238 - accuracy: 0.7900 - f1: 0.7767\n",
            "Epoch 65: val_f1 did not improve from 0.79030\n",
            "57/57 [==============================] - 44s 767ms/step - loss: 0.5238 - accuracy: 0.7900 - f1: 0.7767 - val_loss: 0.5973 - val_accuracy: 0.7769 - val_f1: 0.7284\n",
            "Epoch 66/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5069 - accuracy: 0.8056 - f1: 0.7967\n",
            "Epoch 66: val_f1 did not improve from 0.79030\n",
            "57/57 [==============================] - 43s 758ms/step - loss: 0.5069 - accuracy: 0.8056 - f1: 0.7967 - val_loss: 0.5669 - val_accuracy: 0.7885 - val_f1: 0.7754\n",
            "Epoch 67/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4991 - accuracy: 0.8100 - f1: 0.7945\n",
            "Epoch 67: val_f1 did not improve from 0.79030\n",
            "57/57 [==============================] - 43s 755ms/step - loss: 0.4991 - accuracy: 0.8100 - f1: 0.7945 - val_loss: 0.5780 - val_accuracy: 0.8000 - val_f1: 0.7723\n",
            "Epoch 68/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4980 - accuracy: 0.7978 - f1: 0.7895\n",
            "Epoch 68: val_f1 did not improve from 0.79030\n",
            "57/57 [==============================] - 43s 758ms/step - loss: 0.4980 - accuracy: 0.7978 - f1: 0.7895 - val_loss: 0.5650 - val_accuracy: 0.7885 - val_f1: 0.7484\n",
            "Epoch 69/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5047 - accuracy: 0.8100 - f1: 0.7992\n",
            "Epoch 69: val_f1 did not improve from 0.79030\n",
            "57/57 [==============================] - 43s 757ms/step - loss: 0.5047 - accuracy: 0.8100 - f1: 0.7992 - val_loss: 0.5587 - val_accuracy: 0.8154 - val_f1: 0.7862\n",
            "Epoch 70/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4943 - accuracy: 0.8133 - f1: 0.7914\n",
            "Epoch 70: val_f1 did not improve from 0.79030\n",
            "57/57 [==============================] - 43s 758ms/step - loss: 0.4943 - accuracy: 0.8133 - f1: 0.7914 - val_loss: 0.5534 - val_accuracy: 0.7885 - val_f1: 0.7890\n",
            "Epoch 71/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4860 - accuracy: 0.8089 - f1: 0.8096\n",
            "Epoch 71: val_f1 did not improve from 0.79030\n",
            "57/57 [==============================] - 41s 716ms/step - loss: 0.4860 - accuracy: 0.8089 - f1: 0.8096 - val_loss: 0.5764 - val_accuracy: 0.7654 - val_f1: 0.7880\n",
            "Epoch 72/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4912 - accuracy: 0.8178 - f1: 0.7913\n",
            "Epoch 72: val_f1 did not improve from 0.79030\n",
            "57/57 [==============================] - 41s 712ms/step - loss: 0.4912 - accuracy: 0.8178 - f1: 0.7913 - val_loss: 0.5722 - val_accuracy: 0.7615 - val_f1: 0.7725\n",
            "Epoch 73/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4961 - accuracy: 0.8100 - f1: 0.7911\n",
            "Epoch 73: val_f1 did not improve from 0.79030\n",
            "57/57 [==============================] - 40s 708ms/step - loss: 0.4961 - accuracy: 0.8100 - f1: 0.7911 - val_loss: 0.5575 - val_accuracy: 0.7577 - val_f1: 0.7662\n",
            "Epoch 74/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4914 - accuracy: 0.8100 - f1: 0.8103\n",
            "Epoch 74: val_f1 improved from 0.79030 to 0.79920, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 41s 723ms/step - loss: 0.4914 - accuracy: 0.8100 - f1: 0.8103 - val_loss: 0.5268 - val_accuracy: 0.8115 - val_f1: 0.7992\n",
            "Epoch 75/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4953 - accuracy: 0.8089 - f1: 0.7996\n",
            "Epoch 75: val_f1 did not improve from 0.79920\n",
            "57/57 [==============================] - 42s 738ms/step - loss: 0.4953 - accuracy: 0.8089 - f1: 0.7996 - val_loss: 0.5403 - val_accuracy: 0.8077 - val_f1: 0.7707\n",
            "Epoch 76/200\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4873 - accuracy: 0.8167 - f1: 0.7916\n",
            "Epoch 76: val_f1 improved from 0.79920 to 0.80892, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 41s 722ms/step - loss: 0.4873 - accuracy: 0.8167 - f1: 0.7916 - val_loss: 0.5491 - val_accuracy: 0.7962 - val_f1: 0.8089\n",
            "Epoch 77/200\n"
          ]
        }
      ],
      "source": [
        "number_of_epochs = 200\n",
        "vgg16_filepath = 'checkpoint/vgg16'+'.h5'\n",
        "vgg16_checkpoint = tf.keras.callbacks.ModelCheckpoint(vgg16_filepath, monitor='val_f1', \n",
        "                                                 mode='max', verbose=1,\n",
        "                                                 save_best_only=True,\n",
        "                                                 save_weights_only=False)\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_f1', mode='max', factor=0.3, patience=3, min_lr=1e-7)\n",
        "\n",
        "vgg16_callbacklist = [vgg16_checkpoint]\n",
        "vgg16_history = vgg16_model_final.fit(train_data_multi, epochs = number_of_epochs ,validation_data = test_data_multi, callbacks=vgg16_callbacklist,verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOubvJPHNJ6-"
      },
      "source": [
        "## Dislay Model training history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UioDsrF4NQUr"
      },
      "outputs": [],
      "source": [
        "print(xception_history.history.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxgGKrbYNj8U"
      },
      "source": [
        "### Summarize history for f1-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pX9Fp2uNpK9"
      },
      "outputs": [],
      "source": [
        "plt.plot(xception_history.history['accuracy'])\n",
        "plt.plot(xception_history.history['val_accuracy'])\n",
        "plt.title('model f1')\n",
        "plt.ylabel('val_f1')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aegsS70IM_cr"
      },
      "source": [
        "## Load checkpoint model for continue training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q631T-GjNDjd",
        "outputId": "55bb9c1c-ea28-41b6-ddc4-eb6c6e450468"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4756 - accuracy: 0.8278 - f1: 0.8060\n",
            "Epoch 1: val_f1 improved from -inf to 0.75587, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 337s 6s/step - loss: 0.4756 - accuracy: 0.8278 - f1: 0.8060 - val_loss: 0.5688 - val_accuracy: 0.7846 - val_f1: 0.7559\n",
            "Epoch 2/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4762 - accuracy: 0.8256 - f1: 0.8165\n",
            "Epoch 2: val_f1 improved from 0.75587 to 0.77107, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 41s 725ms/step - loss: 0.4762 - accuracy: 0.8256 - f1: 0.8165 - val_loss: 0.5370 - val_accuracy: 0.7923 - val_f1: 0.7711\n",
            "Epoch 3/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4509 - accuracy: 0.8356 - f1: 0.8299\n",
            "Epoch 3: val_f1 improved from 0.77107 to 0.78583, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 41s 718ms/step - loss: 0.4509 - accuracy: 0.8356 - f1: 0.8299 - val_loss: 0.5274 - val_accuracy: 0.7769 - val_f1: 0.7858\n",
            "Epoch 4/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4884 - accuracy: 0.8100 - f1: 0.7905\n",
            "Epoch 4: val_f1 did not improve from 0.78583\n",
            "57/57 [==============================] - 40s 710ms/step - loss: 0.4884 - accuracy: 0.8100 - f1: 0.7905 - val_loss: 0.5601 - val_accuracy: 0.7769 - val_f1: 0.7708\n",
            "Epoch 5/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4939 - accuracy: 0.7989 - f1: 0.7995\n",
            "Epoch 5: val_f1 did not improve from 0.78583\n",
            "57/57 [==============================] - 40s 698ms/step - loss: 0.4939 - accuracy: 0.7989 - f1: 0.7995 - val_loss: 0.5384 - val_accuracy: 0.8000 - val_f1: 0.7655\n",
            "Epoch 6/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4747 - accuracy: 0.8122 - f1: 0.8039\n",
            "Epoch 6: val_f1 improved from 0.78583 to 0.79849, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 41s 721ms/step - loss: 0.4747 - accuracy: 0.8122 - f1: 0.8039 - val_loss: 0.5119 - val_accuracy: 0.7923 - val_f1: 0.7985\n",
            "Epoch 7/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4669 - accuracy: 0.8300 - f1: 0.8139\n",
            "Epoch 7: val_f1 did not improve from 0.79849\n",
            "57/57 [==============================] - 40s 708ms/step - loss: 0.4669 - accuracy: 0.8300 - f1: 0.8139 - val_loss: 0.5244 - val_accuracy: 0.8077 - val_f1: 0.7892\n",
            "Epoch 8/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4527 - accuracy: 0.8367 - f1: 0.8318\n",
            "Epoch 8: val_f1 improved from 0.79849 to 0.81842, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 40s 710ms/step - loss: 0.4527 - accuracy: 0.8367 - f1: 0.8318 - val_loss: 0.5453 - val_accuracy: 0.8077 - val_f1: 0.8184\n",
            "Epoch 9/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4617 - accuracy: 0.8300 - f1: 0.8135\n",
            "Epoch 9: val_f1 did not improve from 0.81842\n",
            "57/57 [==============================] - 40s 709ms/step - loss: 0.4617 - accuracy: 0.8300 - f1: 0.8135 - val_loss: 0.5421 - val_accuracy: 0.7808 - val_f1: 0.7704\n",
            "Epoch 10/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4603 - accuracy: 0.8300 - f1: 0.8154\n",
            "Epoch 10: val_f1 did not improve from 0.81842\n",
            "57/57 [==============================] - 41s 724ms/step - loss: 0.4603 - accuracy: 0.8300 - f1: 0.8154 - val_loss: 0.5698 - val_accuracy: 0.7962 - val_f1: 0.7563\n",
            "Epoch 11/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4648 - accuracy: 0.8267 - f1: 0.8094\n",
            "Epoch 11: val_f1 did not improve from 0.81842\n",
            "57/57 [==============================] - 41s 712ms/step - loss: 0.4648 - accuracy: 0.8267 - f1: 0.8094 - val_loss: 0.5158 - val_accuracy: 0.8077 - val_f1: 0.7861\n",
            "Epoch 12/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4764 - accuracy: 0.8200 - f1: 0.8140\n",
            "Epoch 12: val_f1 did not improve from 0.81842\n",
            "57/57 [==============================] - 40s 707ms/step - loss: 0.4764 - accuracy: 0.8200 - f1: 0.8140 - val_loss: 0.5328 - val_accuracy: 0.7962 - val_f1: 0.7950\n",
            "Epoch 13/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4721 - accuracy: 0.8211 - f1: 0.8114\n",
            "Epoch 13: val_f1 did not improve from 0.81842\n",
            "57/57 [==============================] - 41s 714ms/step - loss: 0.4721 - accuracy: 0.8211 - f1: 0.8114 - val_loss: 0.5393 - val_accuracy: 0.8000 - val_f1: 0.7887\n",
            "Epoch 14/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4561 - accuracy: 0.8378 - f1: 0.8351\n",
            "Epoch 14: val_f1 did not improve from 0.81842\n",
            "57/57 [==============================] - 41s 716ms/step - loss: 0.4561 - accuracy: 0.8378 - f1: 0.8351 - val_loss: 0.5184 - val_accuracy: 0.8077 - val_f1: 0.7936\n",
            "Epoch 15/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4651 - accuracy: 0.8233 - f1: 0.8148\n",
            "Epoch 15: val_f1 did not improve from 0.81842\n",
            "57/57 [==============================] - 40s 708ms/step - loss: 0.4651 - accuracy: 0.8233 - f1: 0.8148 - val_loss: 0.5328 - val_accuracy: 0.7846 - val_f1: 0.7964\n",
            "Epoch 16/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4623 - accuracy: 0.8122 - f1: 0.8112\n",
            "Epoch 16: val_f1 did not improve from 0.81842\n",
            "57/57 [==============================] - 40s 711ms/step - loss: 0.4623 - accuracy: 0.8122 - f1: 0.8112 - val_loss: 0.5233 - val_accuracy: 0.8077 - val_f1: 0.8029\n",
            "Epoch 17/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.8200 - f1: 0.8013\n",
            "Epoch 17: val_f1 did not improve from 0.81842\n",
            "57/57 [==============================] - 40s 702ms/step - loss: 0.4748 - accuracy: 0.8200 - f1: 0.8013 - val_loss: 0.5076 - val_accuracy: 0.8231 - val_f1: 0.8050\n",
            "Epoch 18/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4419 - accuracy: 0.8356 - f1: 0.8295\n",
            "Epoch 18: val_f1 did not improve from 0.81842\n",
            "57/57 [==============================] - 40s 694ms/step - loss: 0.4419 - accuracy: 0.8356 - f1: 0.8295 - val_loss: 0.5135 - val_accuracy: 0.8192 - val_f1: 0.8029\n",
            "Epoch 19/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4520 - accuracy: 0.8233 - f1: 0.8033\n",
            "Epoch 19: val_f1 improved from 0.81842 to 0.81943, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 40s 710ms/step - loss: 0.4520 - accuracy: 0.8233 - f1: 0.8033 - val_loss: 0.5182 - val_accuracy: 0.8192 - val_f1: 0.8194\n",
            "Epoch 20/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4629 - accuracy: 0.8278 - f1: 0.8164\n",
            "Epoch 20: val_f1 did not improve from 0.81943\n",
            "57/57 [==============================] - 40s 699ms/step - loss: 0.4629 - accuracy: 0.8278 - f1: 0.8164 - val_loss: 0.5483 - val_accuracy: 0.7962 - val_f1: 0.7925\n",
            "Epoch 21/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4576 - accuracy: 0.8189 - f1: 0.8188\n",
            "Epoch 21: val_f1 did not improve from 0.81943\n",
            "57/57 [==============================] - 40s 700ms/step - loss: 0.4576 - accuracy: 0.8189 - f1: 0.8188 - val_loss: 0.4954 - val_accuracy: 0.7962 - val_f1: 0.7951\n",
            "Epoch 22/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4449 - accuracy: 0.8344 - f1: 0.8307\n",
            "Epoch 22: val_f1 did not improve from 0.81943\n",
            "57/57 [==============================] - 40s 701ms/step - loss: 0.4449 - accuracy: 0.8344 - f1: 0.8307 - val_loss: 0.5175 - val_accuracy: 0.8231 - val_f1: 0.8090\n",
            "Epoch 23/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4462 - accuracy: 0.8267 - f1: 0.8191\n",
            "Epoch 23: val_f1 did not improve from 0.81943\n",
            "57/57 [==============================] - 40s 696ms/step - loss: 0.4462 - accuracy: 0.8267 - f1: 0.8191 - val_loss: 0.5248 - val_accuracy: 0.7923 - val_f1: 0.8045\n",
            "Epoch 24/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4512 - accuracy: 0.8289 - f1: 0.8228\n",
            "Epoch 24: val_f1 did not improve from 0.81943\n",
            "57/57 [==============================] - 40s 696ms/step - loss: 0.4512 - accuracy: 0.8289 - f1: 0.8228 - val_loss: 0.5283 - val_accuracy: 0.7885 - val_f1: 0.7910\n",
            "Epoch 25/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4492 - accuracy: 0.8422 - f1: 0.8346\n",
            "Epoch 25: val_f1 did not improve from 0.81943\n",
            "57/57 [==============================] - 40s 697ms/step - loss: 0.4492 - accuracy: 0.8422 - f1: 0.8346 - val_loss: 0.5231 - val_accuracy: 0.8154 - val_f1: 0.8070\n",
            "Epoch 26/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4337 - accuracy: 0.8478 - f1: 0.8337\n",
            "Epoch 26: val_f1 did not improve from 0.81943\n",
            "57/57 [==============================] - 40s 697ms/step - loss: 0.4337 - accuracy: 0.8478 - f1: 0.8337 - val_loss: 0.5259 - val_accuracy: 0.7731 - val_f1: 0.7644\n",
            "Epoch 27/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4613 - accuracy: 0.8211 - f1: 0.8157\n",
            "Epoch 27: val_f1 did not improve from 0.81943\n",
            "57/57 [==============================] - 40s 696ms/step - loss: 0.4613 - accuracy: 0.8211 - f1: 0.8157 - val_loss: 0.5106 - val_accuracy: 0.8154 - val_f1: 0.7913\n",
            "Epoch 28/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4405 - accuracy: 0.8478 - f1: 0.8277\n",
            "Epoch 28: val_f1 did not improve from 0.81943\n",
            "57/57 [==============================] - 40s 695ms/step - loss: 0.4405 - accuracy: 0.8478 - f1: 0.8277 - val_loss: 0.4984 - val_accuracy: 0.7962 - val_f1: 0.7964\n",
            "Epoch 29/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4379 - accuracy: 0.8422 - f1: 0.8260\n",
            "Epoch 29: val_f1 did not improve from 0.81943\n",
            "57/57 [==============================] - 40s 693ms/step - loss: 0.4379 - accuracy: 0.8422 - f1: 0.8260 - val_loss: 0.5010 - val_accuracy: 0.8077 - val_f1: 0.7825\n",
            "Epoch 30/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4444 - accuracy: 0.8289 - f1: 0.8195\n",
            "Epoch 30: val_f1 did not improve from 0.81943\n",
            "57/57 [==============================] - 41s 721ms/step - loss: 0.4444 - accuracy: 0.8289 - f1: 0.8195 - val_loss: 0.5150 - val_accuracy: 0.8038 - val_f1: 0.7972\n",
            "Epoch 31/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.8400 - f1: 0.8224\n",
            "Epoch 31: val_f1 did not improve from 0.81943\n",
            "57/57 [==============================] - 41s 723ms/step - loss: 0.4377 - accuracy: 0.8400 - f1: 0.8224 - val_loss: 0.5342 - val_accuracy: 0.7885 - val_f1: 0.7926\n",
            "Epoch 32/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4453 - accuracy: 0.8211 - f1: 0.8191\n",
            "Epoch 32: val_f1 improved from 0.81943 to 0.83019, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 41s 719ms/step - loss: 0.4453 - accuracy: 0.8211 - f1: 0.8191 - val_loss: 0.4931 - val_accuracy: 0.8308 - val_f1: 0.8302\n",
            "Epoch 33/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.8300 - f1: 0.8267\n",
            "Epoch 33: val_f1 did not improve from 0.83019\n",
            "57/57 [==============================] - 40s 711ms/step - loss: 0.4377 - accuracy: 0.8300 - f1: 0.8267 - val_loss: 0.4958 - val_accuracy: 0.8077 - val_f1: 0.7934\n",
            "Epoch 34/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4303 - accuracy: 0.8444 - f1: 0.8319\n",
            "Epoch 34: val_f1 did not improve from 0.83019\n",
            "57/57 [==============================] - 40s 702ms/step - loss: 0.4303 - accuracy: 0.8444 - f1: 0.8319 - val_loss: 0.4821 - val_accuracy: 0.7923 - val_f1: 0.7918\n",
            "Epoch 35/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4234 - accuracy: 0.8411 - f1: 0.8324\n",
            "Epoch 35: val_f1 did not improve from 0.83019\n",
            "57/57 [==============================] - 40s 711ms/step - loss: 0.4234 - accuracy: 0.8411 - f1: 0.8324 - val_loss: 0.5068 - val_accuracy: 0.8115 - val_f1: 0.8112\n",
            "Epoch 36/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4287 - accuracy: 0.8344 - f1: 0.8316\n",
            "Epoch 36: val_f1 did not improve from 0.83019\n",
            "57/57 [==============================] - 39s 693ms/step - loss: 0.4287 - accuracy: 0.8344 - f1: 0.8316 - val_loss: 0.4871 - val_accuracy: 0.8308 - val_f1: 0.8254\n",
            "Epoch 37/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4398 - accuracy: 0.8300 - f1: 0.8275\n",
            "Epoch 37: val_f1 improved from 0.83019 to 0.83387, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 40s 709ms/step - loss: 0.4398 - accuracy: 0.8300 - f1: 0.8275 - val_loss: 0.5043 - val_accuracy: 0.8231 - val_f1: 0.8339\n",
            "Epoch 38/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4256 - accuracy: 0.8456 - f1: 0.8345\n",
            "Epoch 38: val_f1 did not improve from 0.83387\n",
            "57/57 [==============================] - 39s 692ms/step - loss: 0.4256 - accuracy: 0.8456 - f1: 0.8345 - val_loss: 0.4884 - val_accuracy: 0.8346 - val_f1: 0.8267\n",
            "Epoch 39/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4143 - accuracy: 0.8467 - f1: 0.8371\n",
            "Epoch 39: val_f1 did not improve from 0.83387\n",
            "57/57 [==============================] - 39s 684ms/step - loss: 0.4143 - accuracy: 0.8467 - f1: 0.8371 - val_loss: 0.4931 - val_accuracy: 0.8115 - val_f1: 0.8006\n",
            "Epoch 40/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4238 - accuracy: 0.8422 - f1: 0.8372\n",
            "Epoch 40: val_f1 did not improve from 0.83387\n",
            "57/57 [==============================] - 39s 681ms/step - loss: 0.4238 - accuracy: 0.8422 - f1: 0.8372 - val_loss: 0.5063 - val_accuracy: 0.8115 - val_f1: 0.7829\n",
            "Epoch 41/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4291 - accuracy: 0.8467 - f1: 0.8342\n",
            "Epoch 41: val_f1 did not improve from 0.83387\n",
            "57/57 [==============================] - 39s 683ms/step - loss: 0.4291 - accuracy: 0.8467 - f1: 0.8342 - val_loss: 0.4912 - val_accuracy: 0.8346 - val_f1: 0.8248\n",
            "Epoch 42/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4228 - accuracy: 0.8367 - f1: 0.8191\n",
            "Epoch 42: val_f1 did not improve from 0.83387\n",
            "57/57 [==============================] - 39s 693ms/step - loss: 0.4228 - accuracy: 0.8367 - f1: 0.8191 - val_loss: 0.5367 - val_accuracy: 0.7885 - val_f1: 0.7898\n",
            "Epoch 43/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4268 - accuracy: 0.8244 - f1: 0.8224\n",
            "Epoch 43: val_f1 did not improve from 0.83387\n",
            "57/57 [==============================] - 40s 712ms/step - loss: 0.4268 - accuracy: 0.8244 - f1: 0.8224 - val_loss: 0.4801 - val_accuracy: 0.8385 - val_f1: 0.8317\n",
            "Epoch 44/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4240 - accuracy: 0.8211 - f1: 0.8247\n",
            "Epoch 44: val_f1 did not improve from 0.83387\n",
            "57/57 [==============================] - 41s 713ms/step - loss: 0.4240 - accuracy: 0.8211 - f1: 0.8247 - val_loss: 0.4623 - val_accuracy: 0.8231 - val_f1: 0.8264\n",
            "Epoch 45/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4287 - accuracy: 0.8411 - f1: 0.8275\n",
            "Epoch 45: val_f1 did not improve from 0.83387\n",
            "57/57 [==============================] - 41s 720ms/step - loss: 0.4287 - accuracy: 0.8411 - f1: 0.8275 - val_loss: 0.4986 - val_accuracy: 0.8077 - val_f1: 0.8068\n",
            "Epoch 46/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4243 - accuracy: 0.8367 - f1: 0.8327\n",
            "Epoch 46: val_f1 did not improve from 0.83387\n",
            "57/57 [==============================] - 41s 722ms/step - loss: 0.4243 - accuracy: 0.8367 - f1: 0.8327 - val_loss: 0.4981 - val_accuracy: 0.8077 - val_f1: 0.8261\n",
            "Epoch 47/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4355 - accuracy: 0.8311 - f1: 0.8290\n",
            "Epoch 47: val_f1 did not improve from 0.83387\n",
            "57/57 [==============================] - 41s 717ms/step - loss: 0.4355 - accuracy: 0.8311 - f1: 0.8290 - val_loss: 0.5172 - val_accuracy: 0.8231 - val_f1: 0.8120\n",
            "Epoch 48/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4025 - accuracy: 0.8556 - f1: 0.8334\n",
            "Epoch 48: val_f1 did not improve from 0.83387\n",
            "57/57 [==============================] - 41s 718ms/step - loss: 0.4025 - accuracy: 0.8556 - f1: 0.8334 - val_loss: 0.5028 - val_accuracy: 0.8154 - val_f1: 0.8049\n",
            "Epoch 49/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4148 - accuracy: 0.8367 - f1: 0.8383\n",
            "Epoch 49: val_f1 did not improve from 0.83387\n",
            "57/57 [==============================] - 41s 717ms/step - loss: 0.4148 - accuracy: 0.8367 - f1: 0.8383 - val_loss: 0.4708 - val_accuracy: 0.8077 - val_f1: 0.7947\n",
            "Epoch 50/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4271 - accuracy: 0.8322 - f1: 0.8336\n",
            "Epoch 50: val_f1 did not improve from 0.83387\n",
            "57/57 [==============================] - 41s 715ms/step - loss: 0.4271 - accuracy: 0.8322 - f1: 0.8336 - val_loss: 0.4872 - val_accuracy: 0.8385 - val_f1: 0.8333\n",
            "Epoch 51/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4101 - accuracy: 0.8489 - f1: 0.8380\n",
            "Epoch 51: val_f1 improved from 0.83387 to 0.84539, saving model to checkpoint/vgg16.h5\n",
            "57/57 [==============================] - 41s 721ms/step - loss: 0.4101 - accuracy: 0.8489 - f1: 0.8380 - val_loss: 0.4709 - val_accuracy: 0.8500 - val_f1: 0.8454\n",
            "Epoch 52/100\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.4144 - accuracy: 0.8389 - f1: 0.8351\n",
            "Epoch 52: val_f1 did not improve from 0.84539\n",
            "57/57 [==============================] - 40s 711ms/step - loss: 0.4144 - accuracy: 0.8389 - f1: 0.8351 - val_loss: 0.5055 - val_accuracy: 0.8115 - val_f1: 0.7848\n",
            "Epoch 53/100\n",
            "19/57 [=========>....................] - ETA: 22s - loss: 0.4448 - accuracy: 0.8158 - f1: 0.8135"
          ]
        }
      ],
      "source": [
        "loaded_model = tf.keras.models.load_model('checkpoint/vgg16.h5', custom_objects={\"f1\": f1 })\n",
        "vgg16_checkpoint = tf.keras.callbacks.ModelCheckpoint('checkpoint/vgg16.h5', monitor='val_f1', \n",
        "                                                 mode='max', verbose=1,\n",
        "                                                 save_best_only=True,\n",
        "                                                 save_weights_only=False)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_f1', mode='max', factor=0.1, patience=3, min_lr=0.00000000001)\n",
        "vgg16_callbacklist = [vgg16_checkpoint]\n",
        "# retraining the model\n",
        "loaded_model.fit(train_data_multi, epochs = 100 ,validation_data = test_data_multi,callbacks=vgg16_callbacklist,verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP8p4puBQaBt"
      },
      "source": [
        "### Predict with testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "7OlbB9v_rse6",
        "outputId": "02764ef4-82e6-47ab-860e-5f8d0faa062e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 260 validated image filenames.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ebe66596-c3d9-47f2-b224-7656e8db704c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>labels</th>\n",
              "      <th>name</th>\n",
              "      <th>predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>REMIS_Image_Dataset/others/837645183007172.jpeg</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>others</td>\n",
              "      <td>Test0.jpg</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>REMIS_Image_Dataset/post/123nhadat_4321799_4.jpg</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>post</td>\n",
              "      <td>Test1.jpg</td>\n",
              "      <td>project</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>REMIS_Image_Dataset/others/10208474191744749.jpeg</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>others</td>\n",
              "      <td>Test2.jpg</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>REMIS_Image_Dataset/investor/rever_bat-dong-sa...</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>investor</td>\n",
              "      <td>Test3.jpg</td>\n",
              "      <td>investor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>REMIS_Image_Dataset/project/duanbatdongsan_pj5...</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>project</td>\n",
              "      <td>Test4.jpg</td>\n",
              "      <td>project</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>REMIS_Image_Dataset/investor/rever_gia-tue_0.jpg</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>investor</td>\n",
              "      <td>Test255.jpg</td>\n",
              "      <td>investor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>REMIS_Image_Dataset/post/123nhadat_4310483_0.jpg</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>post</td>\n",
              "      <td>Test256.jpg</td>\n",
              "      <td>post</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>REMIS_Image_Dataset/others/10200930046625836.jpeg</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>others</td>\n",
              "      <td>Test257.jpg</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>REMIS_Image_Dataset/others/1047558682015820.jpeg</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>others</td>\n",
              "      <td>Test258.jpg</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>REMIS_Image_Dataset/post/123nhadat_4320411_0.jpg</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>post</td>\n",
              "      <td>Test259.jpg</td>\n",
              "      <td>post</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>260 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebe66596-c3d9-47f2-b224-7656e8db704c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ebe66596-c3d9-47f2-b224-7656e8db704c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ebe66596-c3d9-47f2-b224-7656e8db704c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  path         label  \\\n",
              "0      REMIS_Image_Dataset/others/837645183007172.jpeg  [0, 1, 0, 0]   \n",
              "1     REMIS_Image_Dataset/post/123nhadat_4321799_4.jpg  [0, 0, 1, 0]   \n",
              "2    REMIS_Image_Dataset/others/10208474191744749.jpeg  [0, 1, 0, 0]   \n",
              "3    REMIS_Image_Dataset/investor/rever_bat-dong-sa...  [1, 0, 0, 0]   \n",
              "4    REMIS_Image_Dataset/project/duanbatdongsan_pj5...  [0, 0, 0, 1]   \n",
              "..                                                 ...           ...   \n",
              "255   REMIS_Image_Dataset/investor/rever_gia-tue_0.jpg  [1, 0, 0, 0]   \n",
              "256   REMIS_Image_Dataset/post/123nhadat_4310483_0.jpg  [0, 0, 1, 0]   \n",
              "257  REMIS_Image_Dataset/others/10200930046625836.jpeg  [0, 1, 0, 0]   \n",
              "258   REMIS_Image_Dataset/others/1047558682015820.jpeg  [0, 1, 0, 0]   \n",
              "259   REMIS_Image_Dataset/post/123nhadat_4320411_0.jpg  [0, 0, 1, 0]   \n",
              "\n",
              "       labels         name   predict  \n",
              "0      others    Test0.jpg    others  \n",
              "1        post    Test1.jpg   project  \n",
              "2      others    Test2.jpg    others  \n",
              "3    investor    Test3.jpg  investor  \n",
              "4     project    Test4.jpg   project  \n",
              "..        ...          ...       ...  \n",
              "255  investor  Test255.jpg  investor  \n",
              "256      post  Test256.jpg      post  \n",
              "257    others  Test257.jpg    others  \n",
              "258    others  Test258.jpg    others  \n",
              "259      post  Test259.jpg      post  \n",
              "\n",
              "[260 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "233 0.8961538461538462 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict_df = pd.read_csv(\"REMIS_Image_Dataset/test_re.csv\")\n",
        "predict_df['labels'] = [predict_df['path'].str.split('\\\\')[i][1] for i in range(len(predict_df['path']))]\n",
        "predict_df['path'] = predict_df['path'].str.replace('Dataset', 'REMIS_Image_Dataset')\n",
        "predict_df['path'] = predict_df['path'].str.replace('\\\\', '/')\n",
        "predict_df['name'] = ['Test' + str(i) + '.jpg' for i in range(len(predict_df['path'])) ]\n",
        "predict_df\n",
        "\n",
        "test_data_gen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "test_data= test_data_generator.flow_from_dataframe(dataframe=predict_df,\n",
        "                                                    directory=\"data/testing\",\n",
        "                                                    x_col=\"name\",\n",
        "                                                    y_col=None,\n",
        "                                                    target_size=(224, 224),\n",
        "                                                    class_mode=None,\n",
        "                                                    batch_size=16,\n",
        "                                                    shuffle=False,\n",
        "                                                    seed=42)\n",
        "test_model = tf.keras.models.load_model('checkpoint/xception125-no-dense_batch16_flip-do20-reduce_lr-from-1e3.h5', custom_objects={\"f1\": f1, \"lr\": lr_metric })\n",
        "test_data.reset()\n",
        "pred=test_model.predict_generator(test_data, verbose=0)\n",
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "labels = (train_data_multi.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]\n",
        "predict_df = predict_df.assign(predict = predictions)\n",
        "display(predict_df)\n",
        "true_count=0\n",
        "false = []\n",
        "for i in range(260):\n",
        "    if predict_df['labels'][i] == predict_df['predict'][i]:\n",
        "        true_count+=1\n",
        "  # else:\n",
        "  #   false.append(predict_df['predict'][i])\n",
        "print(true_count, true_count/260, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7Y44h4T07s7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "model_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
